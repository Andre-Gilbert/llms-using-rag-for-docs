

pandas.read_json#


pandas.read_json(path_or_buf, *, orient=None, typ='frame', dtype=None, convert_axes=None, convert_dates=True, keep_default_dates=True, precise_float=False, date_unit=None, encoding=None, encoding_errors='strict', lines=False, chunksize=None, compression='infer', nrows=None, storage_options=None, dtype_backend=_NoDefault.no_default, engine='ujson')[source]#
Convert a JSON string to pandas object.

Parameters:

path_or_bufa valid JSON str, path object or file-like objectAny valid string path is acceptable. The string could be a URL. Valid
URL schemes include http, ftp, s3, and file. For file URLs, a host is
expected. A local file could be:
file://localhost/path/to/table.json.
If you want to pass in a path object, pandas accepts any
os.PathLike.
By file-like object, we refer to objects with a read() method,
such as a file handle (e.g. via builtin open function)
or StringIO.

Deprecated since version 2.1.0: Passing json literal strings is deprecated.


orientstr, optionalIndication of expected JSON string format.
Compatible JSON strings can be produced by to_json() with a
corresponding orient value.
The set of possible orients is:

'split' : dict like
{index -> [index], columns -> [columns], data -> [values]}
'records' : list like
[{column -> value}, ... , {column -> value}]
'index' : dict like {index -> {column -> value}}
'columns' : dict like {column -> {index -> value}}
'values' : just the values array
'table' : dict like {'schema': {schema}, 'data': {data}}

The allowed and default values depend on the value
of the typ parameter.

when typ == 'series',

allowed orients are {'split','records','index'}
default is 'index'
The Series index must be unique for orient 'index'.


when typ == 'frame',

allowed orients are {'split','records','index',
'columns','values', 'table'}
default is 'columns'
The DataFrame index must be unique for orients 'index' and
'columns'.
The DataFrame columns must be unique for orients 'index',
'columns', and 'records'.




typ{âframeâ, âseriesâ}, default âframeâThe type of object to recover.

dtypebool or dict, default NoneIf True, infer dtypes; if a dict of column to dtype, then use those;
if False, then donât infer dtypes at all, applies only to the data.
For all orient values except 'table', default is True.

convert_axesbool, default NoneTry to convert the axes to the proper dtypes.
For all orient values except 'table', default is True.

convert_datesbool or list of str, default TrueIf True then default datelike columns may be converted (depending on
keep_default_dates).
If False, no dates will be converted.
If a list of column names, then those columns will be converted and
default datelike columns may also be converted (depending on
keep_default_dates).

keep_default_datesbool, default TrueIf parsing dates (convert_dates is not False), then try to parse the
default datelike columns.
A column label is datelike if

it ends with '_at',
it ends with '_time',
it begins with 'timestamp',
it is 'modified', or
it is 'date'.


precise_floatbool, default FalseSet to enable usage of higher precision (strtod) function when
decoding string to double values. Default (False) is to use fast but
less precise builtin functionality.

date_unitstr, default NoneThe timestamp unit to detect if converting dates. The default behaviour
is to try and detect the correct precision, but if this is not desired
then pass one of âsâ, âmsâ, âusâ or ânsâ to force parsing only seconds,
milliseconds, microseconds or nanoseconds respectively.

encodingstr, default is âutf-8âThe encoding to use to decode py3 bytes.

encoding_errorsstr, optional, default âstrictâHow encoding errors are treated. List of possible values .

New in version 1.3.0.


linesbool, default FalseRead the file as a json object per line.

chunksizeint, optionalReturn JsonReader object for iteration.
See the line-delimited json docs
for more information on chunksize.
This can only be passed if lines=True.
If this is None, the file will be read into memory all at once.

Changed in version 1.2: JsonReader is a context manager.


compressionstr or dict, default âinferâFor on-the-fly decompression of on-disk data. If âinferâ and âpath_or_bufâ is
path-like, then detect compression from the following extensions: â.gzâ,
â.bz2â, â.zipâ, â.xzâ, â.zstâ, â.tarâ, â.tar.gzâ, â.tar.xzâ or â.tar.bz2â
(otherwise no compression).
If using âzipâ or âtarâ, the ZIP file must contain only one data file to be read in.
Set to None for no decompression.
Can also be a dict with key 'method' set
to one of {'zip', 'gzip', 'bz2', 'zstd', 'xz', 'tar'} and
other key-value pairs are forwarded to
zipfile.ZipFile, gzip.GzipFile,
bz2.BZ2File, zstandard.ZstdDecompressor, lzma.LZMAFile or
tarfile.TarFile, respectively.
As an example, the following could be passed for Zstandard decompression using a
custom compression dictionary:
compression={'method': 'zstd', 'dict_data': my_compression_dict}.

New in version 1.5.0: Added support for .tar files.


Changed in version 1.4.0: Zstandard support.


nrowsint, optionalThe number of lines from the line-delimited jsonfile that has to be read.
This can only be passed if lines=True.
If this is None, all the rows will be returned.

storage_optionsdict, optionalExtra options that make sense for a particular storage connection, e.g.
host, port, username, password, etc. For HTTP(S) URLs the key-value pairs
are forwarded to urllib.request.Request as header options. For other
URLs (e.g. starting with âs3://â, and âgcs://â) the key-value pairs are
forwarded to fsspec.open. Please see fsspec and urllib for more
details, and for more examples on storage options refer here.

New in version 1.2.0.


dtype_backend{ânumpy_nullableâ, âpyarrowâ}, default ânumpy_nullableâBack-end data type applied to the resultant DataFrame
(still experimental). Behaviour is as follows:

"numpy_nullable": returns nullable-dtype-backed DataFrame
(default).
"pyarrow": returns pyarrow-backed nullable ArrowDtype
DataFrame.


New in version 2.0.


engine{âujsonâ, âpyarrowâ}, default âujsonâParser engine to use. The "pyarrow" engine is only available when
lines=True.

New in version 2.0.




Returns:

Series, DataFrame, or pandas.api.typing.JsonReaderA JsonReader is returned when chunksize is not 0 or None.
Otherwise, the type returned depends on the value of typ.





See also

DataFrame.to_jsonConvert a DataFrame to a JSON string.

Series.to_jsonConvert a Series to a JSON string.

json_normalizeNormalize semi-structured JSON data into a flat table.



Notes
Specific to orient='table', if a DataFrame with a literal
Index name of index gets written with to_json(), the
subsequent read operation will incorrectly set the Index name to
None. This is because index is also used by DataFrame.to_json()
to denote a missing Index name, and the subsequent
read_json() operation cannot distinguish between the two. The same
limitation is encountered with a MultiIndex and any names
beginning with 'level_'.
Examples
>>> from io import StringIO
>>> df = pd.DataFrame([['a', 'b'], ['c', 'd']],
...                   index=['row 1', 'row 2'],
...                   columns=['col 1', 'col 2'])


Encoding/decoding a Dataframe using 'split' formatted JSON:
>>> df.to_json(orient='split')
    '{"columns":["col 1","col 2"],"index":["row 1","row 2"],"data":[["a","b"],["c","d"]]}'
>>> pd.read_json(StringIO(_), orient='split')
      col 1 col 2
row 1     a     b
row 2     c     d


Encoding/decoding a Dataframe using 'index' formatted JSON:
>>> df.to_json(orient='index')
'{"row 1":{"col 1":"a","col 2":"b"},"row 2":{"col 1":"c","col 2":"d"}}'


>>> pd.read_json(StringIO(_), orient='index')
      col 1 col 2
row 1     a     b
row 2     c     d


Encoding/decoding a Dataframe using 'records' formatted JSON.
Note that index labels are not preserved with this encoding.
>>> df.to_json(orient='records')
'[{"col 1":"a","col 2":"b"},{"col 1":"c","col 2":"d"}]'
>>> pd.read_json(StringIO(_), orient='records')
  col 1 col 2
0     a     b
1     c     d


Encoding with Table Schema
>>> df.to_json(orient='table')
    '{"schema":{"fields":[{"name":"index","type":"string"},{"name":"col 1","type":"string"},{"name":"col 2","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":"row 1","col 1":"a","col 2":"b"},{"index":"row 2","col 1":"c","col 2":"d"}]}'





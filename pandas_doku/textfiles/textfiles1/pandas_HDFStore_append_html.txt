

pandas.HDFStore.append#


HDFStore.append(key, value, format=None, axes=None, index=True, append=True, complib=None, complevel=None, columns=None, min_itemsize=None, nan_rep=None, chunksize=None, expectedrows=None, dropna=None, data_columns=None, encoding=None, errors='strict')[source]#
Append to Table in file.
Node must already exist and be Table format.

Parameters:

keystr
value{Series, DataFrame}
formatâtableâ is the defaultFormat to use when storing object in HDFStore. Value can be one of:

'table'Table format. Write as a PyTables Table structure which may perform
worse but allow more flexible operations like searching / selecting
subsets of the data.



indexbool, default TrueWrite DataFrame index as a column.

appendbool, default TrueAppend the input data to the existing.

data_columnslist of columns, or True, default NoneList of columns to create as indexed data columns for on-disk
queries, or True to use all columns. By default only the axes
of the object are indexed. See here.

min_itemsizedict of columns that specify minimum str sizes
nan_repstr to use as str nan representation
chunksizesize to chunk the writing
expectedrowsexpected TOTAL row size of this table
encodingdefault None, provide an encoding for str
dropnabool, default False, optionalDo not write an ALL nan row to the store settable
by the option âio.hdf.dropna_tableâ.




Notes
Does not check if data being appended overlaps with existing
data in the table, so be careful
Examples
>>> df1 = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 'B'])
>>> store = pd.HDFStore("store.h5", 'w')  
>>> store.put('data', df1, format='table')  
>>> df2 = pd.DataFrame([[5, 6], [7, 8]], columns=['A', 'B'])
>>> store.append('data', df2)  
>>> store.close()  
   A  B
0  1  2
1  3  4
0  5  6
1  7  8





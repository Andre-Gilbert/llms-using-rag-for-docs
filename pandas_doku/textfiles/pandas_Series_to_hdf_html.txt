

pandas.Series.to_hdf#


Series.to_hdf(path_or_buf, key, mode='a', complevel=None, complib=None, append=False, format=None, index=True, min_itemsize=None, nan_rep=None, dropna=None, data_columns=None, errors='strict', encoding='UTF-8')[source]#
Write the contained data to an HDF5 file using HDFStore.
Hierarchical Data Format (HDF) is self-describing, allowing an
application to interpret the structure and contents of a file with
no outside information. One HDF file can hold a mix of related objects
which can be accessed as a group or as individual objects.
In order to add another DataFrame or Series to an existing HDF file
please use append mode and a different a key.

Warning
One can store a subclass of DataFrame or Series to HDF5,
but the type of the subclass is lost upon storing.

For more information see the user guide.

Parameters:

path_or_bufstr or pandas.HDFStoreFile path or HDFStore object.

keystrIdentifier for the group in the store.

mode{âaâ, âwâ, âr+â}, default âaâMode to open file:

âwâ: write, a new file is created (an existing file with
the same name would be deleted).
âaâ: append, an existing file is opened for reading and
writing, and if the file does not exist it is created.
âr+â: similar to âaâ, but the file must already exist.


complevel{0-9}, default NoneSpecifies a compression level for data.
A value of 0 or None disables compression.

complib{âzlibâ, âlzoâ, âbzip2â, âbloscâ}, default âzlibâSpecifies the compression library to be used.
These additional compressors for Blosc are supported
(default if no compressor specified: âblosc:blosclzâ):
{âblosc:blosclzâ, âblosc:lz4â, âblosc:lz4hcâ, âblosc:snappyâ,
âblosc:zlibâ, âblosc:zstdâ}.
Specifying a compression library which is not available issues
a ValueError.

appendbool, default FalseFor Table formats, append the input data to the existing.

format{âfixedâ, âtableâ, None}, default âfixedâPossible values:

âfixedâ: Fixed format. Fast writing/reading. Not-appendable,
nor searchable.
âtableâ: Table format. Write as a PyTables Table structure
which may perform worse but allow more flexible operations
like searching / selecting subsets of the data.
If None, pd.get_option(âio.hdf.default_formatâ) is checked,
followed by fallback to âfixedâ.


indexbool, default TrueWrite DataFrame index as a column.

min_itemsizedict or int, optionalMap column names to minimum string sizes for columns.

nan_repAny, optionalHow to represent null values as str.
Not allowed with append=True.

dropnabool, default False, optionalRemove missing values.

data_columnslist of columns or True, optionalList of columns to create as indexed data columns for on-disk
queries, or True to use all columns. By default only the axes
of the object are indexed. See
Query via data columns. for
more information.
Applicable only to format=âtableâ.

errorsstr, default âstrictâSpecifies how encoding and decoding errors are to be handled.
See the errors argument for open() for a full list
of options.

encodingstr, default âUTF-8â




See also

read_hdfRead from HDF file.

DataFrame.to_orcWrite a DataFrame to the binary orc format.

DataFrame.to_parquetWrite a DataFrame to the binary parquet format.

DataFrame.to_sqlWrite to a SQL table.

DataFrame.to_featherWrite out feather-format for DataFrames.

DataFrame.to_csvWrite out to a csv file.



Examples
>>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},
...                   index=['a', 'b', 'c'])  
>>> df.to_hdf('data.h5', key='df', mode='w')  


We can add another object to the same file:
>>> s = pd.Series([1, 2, 3, 4])  
>>> s.to_hdf('data.h5', key='s')  


Reading from HDF file:
>>> pd.read_hdf('data.h5', 'df')  
A  B
a  1  4
b  2  5
c  3  6
>>> pd.read_hdf('data.h5', 's')  
0    1
1    2
2    3
3    4
dtype: int64





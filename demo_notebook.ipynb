{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves the purpose of demonstrating how the Retriaval Augmented Generation improves the LLM code generation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM code creation without RAG and CoALA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we import the necessary libraries and create an agent object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and agent creation\n",
    "import pandas as pd\n",
    "from llms.agents.react import ReActAgent\n",
    "from llms.clients.gpt import GPTClient\n",
    "from llms.settings import settings\n",
    "\n",
    "client = GPTClient(\n",
    "    client_id=settings.CLIENT_ID,\n",
    "    client_secret=settings.CLIENT_SECRET,\n",
    "    auth_url=settings.AUTH_URL,\n",
    "    api_base=settings.API_BASE,\n",
    "    deployment_id=\"gpt-4-32k\",\n",
    "    max_response_tokens=1000,\n",
    "    temperature=0.0,\n",
    ")\n",
    "agent = ReActAgent(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define a prompt and ask the agent without RAG and CoALA implemented for the code. Then we execute the function code and save the function that the agent generated under `agent_func`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Please return the rolling rank(3) of this Series [1, 4, 2, 3, 5, 3]. Make sure to code your solution using the pandas lib.\"\"\"\n",
    "\n",
    "generated_code = agent.run(prompt)\n",
    "\n",
    "namespace_agent = {}\n",
    "exec(generated_code, namespace_agent)\n",
    "agent_func = namespace_agent['response_function']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define our input and the expected function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = pd.Series([1, 4, 2, 3, 5, 3])\n",
    "\n",
    "def expected_func(input):\n",
    "    result = input.rolling(3).rank()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the results of the two functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Desired result:')\n",
    "print(expected_func(input))\n",
    "print()\n",
    "print('Agent result:')\n",
    "print(agent_func(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM code creation with RAG and CoALA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating a new LLM agent that is augmented by RAG and CoALA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the FAISS vector storage for the retrieval augmented generation and CoALA\n",
    "from llms.rag.faiss import FAISS\n",
    "from llms.rag.coala import CoALA\n",
    "\n",
    "docs_vector_store = FAISS.load_local(\"embeddings/semantic/\", \"embeddings_DistanceMetric.MAX_INNER_PRODUCT_search_results_3_score_threshold_0.0_chunk_size_512_weighted_average_True\", client)\n",
    "\n",
    "code_vector_store = FAISS.load_local(\"embeddings/episodic/\", \"embeddings_DistanceMetric.MAX_INNER_PRODUCT_search_results_3_score_threshold_0.0_chunk_size_512_weighted_average_True\", client)\n",
    "\n",
    "coala = CoALA(docs_vector_store, code_vector_store)\n",
    "\n",
    "rag_agent = ReActAgent(client, rag=docs_vector_store)\n",
    "coala_agent = ReActAgent(client, rag=coala)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = {\n",
    "    \"RAG\": rag,\n",
    "    \"CoALA\": coala_rag\n",
    "}\n",
    "\n",
    "rag_agent = ReActAgent(client, rag=None, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reminder\n",
    "prompt = \"\"\"Please return the rolling rank(3) of this Series [1, 4, 2, 3, 5, 3]. Make sure to code your solution using the pandas lib.\"\"\"\n",
    "\n",
    "generated_code_rag = rag_agent.run(prompt)\n",
    "\n",
    "namespace_rag_agent = {}\n",
    "exec(generated_code_rag, namespace_rag_agent)\n",
    "rag_agent_func = namespace_rag_agent['response_function']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the `input` and `expected_func` stay the same, we can now compare the results of the rag enhanced agent with the expected result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = pd.Series([1, 4, 2, 3, 5, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Desired result:')\n",
    "print(expected_func(input))\n",
    "print()\n",
    "print('Rag enhanced agent result:')\n",
    "print(rag_agent_func(input))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

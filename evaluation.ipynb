{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of RAG architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/llms-using-rag-for-docs/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llms.rag.faiss import FAISS\n",
    "from llms.rag.coala import CoALA\n",
    "from llms.agents.react import ReActAgent\n",
    "from llms.clients.gpt import GPTClient\n",
    "from llms.settings import settings\n",
    "from llms.rag.tools import Tools\n",
    "from llms.rag.faiss import DistanceMetric\n",
    "from llms.evaluation.code import evaluate_code_generation, ConfigGrid, RAG, RAGRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4_client = GPTClient(\n",
    "    client_id=settings.CLIENT_ID,\n",
    "    client_secret=settings.CLIENT_SECRET,\n",
    "    auth_url=settings.AUTH_URL,\n",
    "    api_base=settings.API_BASE,\n",
    "    deployment_id='gpt-4-32k',\n",
    "    max_response_tokens=100,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "gpt_35_client = GPTClient(\n",
    "    client_id=settings.CLIENT_ID,\n",
    "    client_secret=settings.CLIENT_SECRET,\n",
    "    auth_url=settings.AUTH_URL,\n",
    "    api_base=settings.API_BASE,\n",
    "    deployment_id='gpt-35-turbo-16k',\n",
    "    max_response_tokens=100,\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    You are an AI assistant who can write code using pandas.\n",
      "    All necessary code that is part of the answer must be in a single python function called response_function.\n",
      "    If you have one argument given to you in the user prompt, write your response function so that it takes one argument.\n",
      "    If you have two arguments given in the user prompt, write your response function so that it takes two arguments.\n",
      "    Do not write any text or code outside this function when constructing an answer or action.\n",
      "    In the first line of code inside the function please always import pandas as pd or pyarrow as pa, depending on what you need.\n",
      "    Pandas, numpy and pyarrow are the only non-standard packages you are allowed to use.\n",
      "\n",
      "    Always use the following JSON response format:\n",
      "    {\n",
      "        \"Question\": the input question you must answer\n",
      "        \"Thought\": you should always think about what to do\n",
      "        \"Action\": \"def response_function(arguments as required by the user prompt):\n",
      "code goes here\"\n",
      "    }\n",
      "    The users system that is interacting with you will then add an observation to the conversation by executing the action.\n",
      "    {\"Observation\": the result of the action}\n",
      "    ... (this Thought/Action/Observation can repeat N times)\n",
      "    When you are confident that you found the final answer and the observation contains positive feedback, answer:\n",
      "    {\n",
      "        \"Thought\": I now know the final answer\n",
      "        \"Answer\": the final Python code to the original input question\n",
      "    }\n",
      "\n",
      "    Do not write any text or code outside the given JSON framework. Also do not write any observations by yourself.\n",
      "    Always escape special characters to enable parsing with json.loads().\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(settings.STANDARD_SYSTEM_INSTRUCTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/4 [00:00<?, ?it/s]\n",
      "13409 - DEBUG - Starting new HTTPS connection (1): business-decision-simulator-experiments-qpti6y8s.authentication.eu12.hana.ondemand.com:443\n",
      "13409 - DEBUG - https://business-decision-simulator-experiments-qpti6y8s.authentication.eu12.hana.ondemand.com:443 \"POST /oauth/token?grant_type=client_credentials HTTP/1.1\" 200 None\n",
      "13409 - DEBUG - Starting new HTTPS connection (1): azure-openai-serv-i057149.cfapps.eu12.hana.ondemand.com:443\n",
      "13409 - DEBUG - https://azure-openai-serv-i057149.cfapps.eu12.hana.ondemand.com:443 \"POST /api/v1/embeddings HTTP/1.1\" 200 19629\n",
      "13409 - DEBUG - Starting new HTTPS connection (1): business-decision-simulator-experiments-qpti6y8s.authentication.eu12.hana.ondemand.com:443\n",
      "13409 - DEBUG - https://business-decision-simulator-experiments-qpti6y8s.authentication.eu12.hana.ondemand.com:443 \"POST /oauth/token?grant_type=client_credentials HTTP/1.1\" 200 None\n",
      "13409 - DEBUG - Starting new HTTPS connection (1): azure-openai-serv-i057149.cfapps.eu12.hana.ondemand.com:443\n",
      "13409 - DEBUG - https://azure-openai-serv-i057149.cfapps.eu12.hana.ondemand.com:443 \"POST /api/v1/embeddings HTTP/1.1\" 200 19589\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]/4 [00:01<00:01,  1.43it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.76it/s]\n"
     ]
    }
   ],
   "source": [
    "config = ConfigGrid(\n",
    "    llms=[gpt_4_client, gpt_35_client],\n",
    "    rag=RAG(\n",
    "        retrievers=[RAGRetriever.CoALA],\n",
    "        distance_metrics=[DistanceMetric.EUCLIDEAN_DISTANCE],\n",
    "        num_search_results=[3],\n",
    "        similarity_search_score_thresholds=[0.0],\n",
    "        texts=[\"Hello\", \"test123\"],\n",
    "        text_chunk_sizes=[128],\n",
    "    )\n",
    ")\n",
    "\n",
    "evaluate_code_generation(config, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms-using-rag-for-docs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
